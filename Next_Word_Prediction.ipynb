{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bf4d0c-2d6e-467a-9e22-313cd53cdc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Parth Sharma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Training GPT-2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3078' max='3078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3078/3078 59:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.961700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.771300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.670700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.613100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.561800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DistilGPT-2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3474393cab47c5a96a327e23942ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3078' max='3078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3078/3078 39:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.937900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.811400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.762600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Add padding token\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(model_name, dataset_path, output_dir, epochs=1):\n",
    "    try:\n",
    "        # Load the pre-trained model\n",
    "        model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "        # Prepare the dataset using Datasets library\n",
    "        dataset = load_dataset('text', data_files=dataset_path)['train']\n",
    "        dataset = dataset.map(lambda examples: tokenizer(examples['text'], truncation=True, padding=True, max_length=128), batched=True)\n",
    "        dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "        # Data collator\n",
    "        data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            overwrite_output_dir=True,\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=4,\n",
    "            save_steps=10_000,\n",
    "            save_total_limit=2,\n",
    "            logging_dir=f\"{output_dir}/logs\",\n",
    "            logging_steps=500,\n",
    "            report_to=\"none\"  # Disable logging for simplicity\n",
    "        )\n",
    "\n",
    "        # Trainer initialization\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "        trainer.save_model(output_dir)\n",
    "\n",
    "        return output_dir\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training {model_name}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Train models and store paths\n",
    "trained_models = {}\n",
    "try:\n",
    "    print(\"Training GPT-2...\")\n",
    "    trained_models['GPT-2'] = train_model('gpt2', 'sherlock.txt', './fine_tuned_gpt2', epochs=1)\n",
    "    print(\"Training DistilGPT-2...\")\n",
    "    trained_models['DistilGPT-2'] = train_model('distilgpt2', 'sherlock.txt', './fine_tuned_distilgpt2', epochs=1)\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {str(e)}\")\n",
    "\n",
    "# Load fine-tuned models if training succeeded\n",
    "models = {}\n",
    "for model_name, path in trained_models.items():\n",
    "    try:\n",
    "        models[model_name] = pipeline('text-generation', model=path, tokenizer=tokenizer, truncation=True, pad_token_id=50256)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {str(e)}\")\n",
    "\n",
    "# Function to generate suggestions\n",
    "def get_model_suggestions(sentence_a, num_words=3):\n",
    "    suggestions = {}\n",
    "    for model_name, generator in models.items():\n",
    "        try:\n",
    "            # Generate next word suggestions\n",
    "            result = generator(\n",
    "                sentence_a,\n",
    "                max_new_tokens=1,  # Generate only the next word\n",
    "                num_return_sequences=num_words,  # Generate multiple suggestions\n",
    "                temperature=0.7,  # Control randomness\n",
    "                top_p=0.9,  # Nucleus sampling\n",
    "                top_k=50,  # Limit token set\n",
    "                do_sample=True  # Enable sampling\n",
    "            )\n",
    "            suggestions[model_name] = [r['generated_text'][len(sentence_a):].strip().split()[0] for r in result]\n",
    "\n",
    "            # Remove duplicates while maintaining order\n",
    "            suggestions[model_name] = list(dict.fromkeys(suggestions[model_name]))\n",
    "        except Exception as e:\n",
    "            suggestions[model_name] = [f\"Error: {str(e)}\"]\n",
    "    return suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b60e42-ebfa-4acb-a9e8-7a32706cbe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.24.174:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:54] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:54] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:54] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:58] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['it', 'not', 'the'], 'DistilGPT-2': ['not', 'you']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ress', 'ain', '.'], 'DistilGPT-2': ['ear', 'ï¿½', 'uc']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['not', 'that', 'it'], 'DistilGPT-2': [',', '.', 'ing']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:28:59] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:59] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:59] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:28:59] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:29:00] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['onder', \"'\"], 'DistilGPT-2': ['ï¿½']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['?', '.'], 'DistilGPT-2': ['-', '!']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:29:00] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:29:00] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:29:00] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['know', 'see', 'think'], 'DistilGPT-2': ['know', 'see', 'have']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['not', 'know', 'think'], 'DistilGPT-2': ['be', 'have', 'know']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:51:28] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:51:30] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', 'what', 'where'], 'DistilGPT-2': ['that']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', 'how', 'that'], 'DistilGPT-2': ['that', 'where']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:32] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['?', 'ove', 'ow'], 'DistilGPT-2': ['oms', 'ose']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ead'], 'DistilGPT-2': ['elt', 'ead', 'uckle']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['irk', 'ite', 'ow'], 'DistilGPT-2': ['ow']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['see', 'know'], 'DistilGPT-2': [',', 'have']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['think', 'know'], 'DistilGPT-2': ['have', 'not', 'know']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['!', '?', ','], 'DistilGPT-2': ['?', '!', ',']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['the', 'it', 'you'], 'DistilGPT-2': ['I', ',']}\n",
      "Suggestions returned to frontend: {'GPT-2': [\"'\"], 'DistilGPT-2': ['ï¿½']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['it', ',', 'this'], 'DistilGPT-2': ['you', 'the', 'ing']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:57:33] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['.', 'ive'], 'DistilGPT-2': ['ressed', 'ellow']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:40] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['ank', ',', 'rave'], 'DistilGPT-2': ['olen', 'ear', 'ance']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:41] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:41] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['it', 'the', 'not'], 'DistilGPT-2': [',', 'not']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:41] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:42] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', 'not', '.'], 'DistilGPT-2': ['with', 'it', 'I']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:42] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:43] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['onder'], 'DistilGPT-2': ['ï¿½', \"'\"]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:43] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:43] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['.', '-', '?'], 'DistilGPT-2': [',', '?']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:43] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:43] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['see', 'know', 'think'], 'DistilGPT-2': ['to', '.', ',']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:58:44] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:58:44] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['think', 'see', 'not'], 'DistilGPT-2': ['know', '.', '?']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:08] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:08] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['not', '?'], 'DistilGPT-2': ['in', '?', ',']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:08] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:08] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:08] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:09] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['-', ','], 'DistilGPT-2': ['!', '?', '.']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['onder'], 'DistilGPT-2': [\"'\", 'ï¿½']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['not', ',', 'it'], 'DistilGPT-2': ['that', '.', 'he']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['a', 'not'], 'DistilGPT-2': ['.', 'it', 'to']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ound', 'oul', '.'], 'DistilGPT-2': ['olen', 'rought', 'ram']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:11] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:11] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['have', 'was', 'should'], 'DistilGPT-2': ['was', 'ï¿½']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:11] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:11] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['was', 'had', ','], 'DistilGPT-2': ['was', 'should', 'think']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:12] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:12] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['venge', 'moment', 'little'], 'DistilGPT-2': ['very', 'man']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:12] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:12] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', 'convinced', 'going'], 'DistilGPT-2': ['afraid', 'the', 'an']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:13] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:13] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['not', 'afraid'], 'DistilGPT-2': ['a', 'in', 'sure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:19] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:19] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['rieved'], 'DistilGPT-2': ['rieved']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['aded', 'bs'], 'DistilGPT-2': ['to']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['-', 'ed', \"'\"], 'DistilGPT-2': [',', '.', 'ed']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:20] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['enough', 'at'], 'DistilGPT-2': ['-', 'enough']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:25] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:25] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['ï¿½'], 'DistilGPT-2': ['I', 'ï¿½']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:37] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:37] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['ï¿½', 'I'], 'DistilGPT-2': ['ï¿½', 'But', 'I']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:38] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['.', 'ark', 'm'], 'DistilGPT-2': ['mmmm', 'ic', 'uff']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:38] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', '.'], 'DistilGPT-2': [',']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:38] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:39] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', '!'], 'DistilGPT-2': ['.', '!', ',']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:47] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['aa', 'm', 'ii'], 'DistilGPT-2': ['m', '.']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:47] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [',', 'ho'], 'DistilGPT-2': ['!']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:48] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:48] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['have', 'are', 'did'], 'DistilGPT-2': ['much', 'are', 'do']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 15:59:57] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 15:59:57] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['I', 'you'], 'DistilGPT-2': ['you']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:44] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:44] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['you'], 'DistilGPT-2': ['you']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['oled', 'ined'], 'DistilGPT-2': ['re', 'ined', 'oled']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['I', 'you'], 'DistilGPT-2': ['you']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:45] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['you'], 'DistilGPT-2': ['you']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['n'], 'DistilGPT-2': [',', '!']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['!', 'uling', 're'], 'DistilGPT-2': [',', '!', 'uls']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['oo', 'ank'], 'DistilGPT-2': ['oo', 'ush', '!']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['I', 'do'], 'DistilGPT-2': ['did', 'your', 'I']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['you', 'is'], 'DistilGPT-2': ['do', 'I', 'you']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['?', 'ï¿½', '!'], 'DistilGPT-2': ['!', ',', '.']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ous', 'her', 're'], 'DistilGPT-2': ['us', 'ous']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ister', 'am'], 'DistilGPT-2': ['iff', 'ew', 'ï¿½']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['are', 'I', 'can'], 'DistilGPT-2': ['it', ',', 'much']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['did', 'do', 'dy'], 'DistilGPT-2': ['much', ',']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['!'], 'DistilGPT-2': ['ho', '!']}\n",
      "Suggestions returned to frontend: {'GPT-2': [',', '!'], 'DistilGPT-2': [',', '.']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:46] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': [','], 'DistilGPT-2': ['!', ',', '.']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['m', 'ii', '.'], 'DistilGPT-2': ['ir', 'm']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['mm', 'm'], 'DistilGPT-2': ['ark', 'mmm', 'm']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"OPTIONS /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['ï¿½'], 'DistilGPT-2': ['ï¿½', 'I']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['enough', 'at'], 'DistilGPT-2': ['-', 'to']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['ï¿½'], 'DistilGPT-2': ['ï¿½', 'I']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['in', 'bs'], 'DistilGPT-2': ['to', 'out']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['zy', '-', 'aming'], 'DistilGPT-2': [',', '!']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['rieved'], 'DistilGPT-2': ['rieved']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['afraid', 'a', 'sure'], 'DistilGPT-2': ['so', 'glad']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [28/Nov/2024 16:01:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions returned to frontend: {'GPT-2': ['afraid', 'of'], 'DistilGPT-2': ['indebted', 'sure', 'going']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['little', 'man', 'few'], 'DistilGPT-2': ['man', 'rather', 'long']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['was', 'had'], 'DistilGPT-2': ['have', 'did', 'found']}\n",
      "Suggestions returned to frontend: {'GPT-2': ['had', 'could', 'was'], 'DistilGPT-2': ['came', 'was', 'had']}\n"
     ]
    }
   ],
   "source": [
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data or 'sentence_a' not in data:\n",
    "            return jsonify({'error': 'Invalid input: sentence_a missing'}), 400\n",
    "\n",
    "        sentence_a = data['sentence_a']\n",
    "        num_words = data.get('num_words', 3)\n",
    "        if not isinstance(num_words, int) or num_words < 1 or num_words > 10:\n",
    "            return jsonify({'error': 'num_words must be an integer between 1 and 10'}), 400\n",
    "\n",
    "        # Get next-word suggestions from models\n",
    "        suggestions = get_model_suggestions(sentence_a, num_words)\n",
    "\n",
    "        print(\"Suggestions returned to frontend:\", suggestions)  # Debugging print\n",
    "\n",
    "        return jsonify({'suggestions': suggestions})\n",
    "    except Exception as e:\n",
    "        print(\"Error in prediction:\", str(e))  # Debugging print\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856efaf5-94ec-43f0-90a9-156da7817563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
